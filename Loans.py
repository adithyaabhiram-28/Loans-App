# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Efoq6Cg-WkRB3noUT17HlcwYNI-9B2s0
"""

import pandas as pd

df = pd.read_csv("hearts.csv")
df.head()

df.isnull().sum()

# Handle missing values
df.dropna(inplace=True)

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
  le = LabelEncoder()
  df[col] = le.fit_transform(df[col])
  label_encoders[col] = le

from sklearn.model_selection import train_test_split

# Define features and target variable
X = df.drop(columns=['target']) # Replace 'target' with actual target column name
y = df['target' ]

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

svm_linear = SVC(kernel='linear', C=1)
svm_linear.fit(X_train, y_train)
y_pred_linear = svm_linear.predict(X_test)

print(svm_linear.score(X_train, y_train))
print(svm_linear.score(X_test, y_test))

svm_poly = SVC(kernel='poly', degree=3, C=1)
svm_poly.fit(X_train, y_train)
y_pred_poly = svm_poly.predict(X_test)

from sklearn.metrics import confusion_matrix, accuracy_score

print(accuracy_score(y_test, y_pred_poly))
print(confusion_matrix(y_test, y_pred_poly))

svm_rbf = SVC(kernel='rbf', C=1, gamma='scale')
svm_rbf.fit(X_train, y_train)
y_pred_rbf = svm_rbf.pr edict(X_test)

print(accuracy_score(y_test, y_pred_rbf))
print(confusion_matrix(y_test, y_pred_rbf))

df1 = pd.read_csv("loans.csv")
df1.head()

df1.isna().sum()

df1.dtypes

df1.shape

for col in df1.columns:
  if df1[col].dtype == 'object':
    df1[col] = df1[col].fillna(df1[col].mode()[0])
  else:
    df1[col] = df1[col].fillna(df1[col].median())

df1.isna().sum()

df1.shape

df1.head()

from sklearn.preprocessing import LabelEncoder

label_encoders = {}
le_self_employed = LabelEncoder()
df1['Self_Employed'] = le_self_employed.fit_transform(df1['Self_Employed'])
label_encoders['Self_Employed'] = le_self_employed

le_loan_status = LabelEncoder()
df1['Loan_Status'] = le_loan_status.fit_transform(df1['Loan_Status'])
label_encoders['Loan_Status'] = le_loan_status

X = df1[['ApplicantIncome','LoanAmount','Credit_History','Self_Employed']]
y = df1['Loan_Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

svm_rbf = SVC(kernel='rbf', C=1, gamma='scale')
svm_rbf.fit(X_train, y_train)
y_pred_rbf = svm_rbf.predict(X_test)

print(accuracy_score(y_test, y_pred_rbf))
print(confusion_matrix(y_test, y_pred_rbf))

df1.plot(kind='scatter', x='ApplicantIncome', y='LoanAmount')

svm_linear = SVC(kernel='linear', C=1)
svm_linear.fit(X_train, y_train)
y_pred_linear = svm_linear.predict(X_test)

print(accuracy_score(y_test, y_pred_linear))
print(confusion_matrix(y_test, y_pred_linear))

eligible_rejected = confusion_matrix(y_test, y_pred_rbf)[1, 0]

risky_approved = confusion_matrix(y_test, y_pred_rbf)[0, 1]

print(f"Number of eligible customers rejected (False Negatives): {eligible_rejected}")
print(f"Number of risky customers approved (False Positives): {risky_approved}")

linear_eligible_rejected = confusion_matrix(y_test, y_pred_linear)[1, 0]
linear_risky_approved = confusion_matrix(y_test, y_pred_linear)[0, 1]

print(f"Number of eligible customers rejected (False Negatives) by Linear SVM: {linear_eligible_rejected}")
print(f"Number of risky customers approved (False Positives) by Linear SVM: {linear_risky_approved}")

def plot_decision_boundary(X, y, classifier, title):
    X_plot = X[:, [0, 1]]

    h = .02
    cmap_light = ListedColormap(['#FAFAFA', '#AFAFAF'])
    cmap_bold = ListedColormap(['#FF0000', '#00FF00'])

    x_min, x_max = X_plot[:, 0].min() - 1, X_plot[:, 0].max() + 1
    y_min, y_max = X_plot[:, 1].min() - 1, X_plot[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    num_features_trained_on = X_train.shape[1]
    mesh_data = np.c_[xx.ravel(), yy.ravel()]

    if num_features_trained_on > 2:
        dummy_features_values = np.mean(X_train[:, 2:], axis=0)
        dummy_features_matrix = np.tile(dummy_features_values, (mesh_data.shape[0], 1))
        mesh_data = np.hstack((mesh_data, dummy_features_matrix))

    Z = classifier.predict(mesh_data)
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(6, 4))
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

    plt.scatter(X_plot[:, 0], X_plot[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=10) # Smaller scatter points
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())
    plt.title(title)
    plt.xlabel('ApplicantIncome (Scaled)')
    plt.ylabel('LoanAmount (Scaled)')
    plt.show()

plot_decision_boundary(X_test, y_test, svm_linear, 'Linear SVM Decision Boundary (ApplicantIncome vs LoanAmount)')

plot_decision_boundary(X_test, y_test, svm_rbf, 'RBF SVM Decision Boundary (ApplicantIncome vs LoanAmount)')

